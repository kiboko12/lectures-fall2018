{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation\n",
    "\n",
    "References:\n",
    "Think Bayes: Bayesian Statistics Made Simple by Allen B. Downey\n",
    "\n",
    "In this lecture, we will go over the basics of estimating the model parameters $\\vec{\\theta}$ that describe some data $D$.  First let's start with a quick review of Bayesian statisics.\n",
    "\n",
    "## Probability\n",
    "\n",
    "A fundamental quantity in statistics is *probability*.  Essentially, a probability is a number between 0 and 1 that describes a degree of belief.  If the probability of a statement $A$ (which we denote $p(A)$) is 1, we have complete certainty that $A$ is true, and if $p(A)=0$, we are certain that $A$ is not true.  Numbers in between 0 and 1 describe a partial degree of certainty -- I might believe there is a $p=0.5$ chance it will rain tomorrow, i.e. whether it rains or not could go either way. Of course, we are 100% certain that it will either rain or it won't, so $p(A)+p(-A) = 1$  If $A$ is instead a continuous variable, e.g. a person's height, we have that $\\int p(A) dA = 1$, since we are certain that the person has some height.  In the continuous case $p(A)$ is now the *probabilility density function* (PDF), with units of $1/[A]$.\n",
    "\n",
    "Another quantity of interest is the *conditional probability*: It's the probability that $A$ is true given some other fixed knowledge $B$. We denote this $p(A|B)$.  In general, $p(A|B)\\neq p(A)$, because the truth of $A$ is not independent of the truth of $B$. If I know it's the month of April, my belief about there being raining weather tomorrow is different from if I know that it's the month of July.  \n",
    "\n",
    "Lastly, we have the *joint probability*: It's the probability that multiple things are true, e.g. that $A$ and $B$ are both true. We denote this probability $p(A,B)$.  __If $A$ and $B$ are *independent*__, $p(A,B)  = p(A)p(B)$. \n",
    "\n",
    "\n",
    "## Bayes' Rule\n",
    "\n",
    "Now we can notice that there is a relation between conditional and joint probabilities.  If we want to know $p(A,B)$, we might be tempted to just compute $p(A)p(B)$, but this is incorrect, because in general $A$ and $B$ are not independent.  Instead of $p(A)$, we need $p(A|B)$, because if $B$ is true, our belief in $A$ changes.  So we have:\n",
    "$$p(A,B) = p(A|B)p(B)$$\n",
    "Of course, $p(A,B) = p(B,A)$, so we can do an exchange of $A$ and $B$ and be left with the same probability.  This yields Bayes' Rule:\n",
    "$$p(A|B)p(B) = p(B|A)p(A)$$.\n",
    "\n",
    "## Bayesian Inference\n",
    "Here's general question we can ask in most any scientific context: \"How likely is a hypothesis $H$ given that I collected data $D$?  We can straighforwardly write this in our mathematical notation: $p(H|D)$.  Using Bayes' Rule, we find:\n",
    "$$p(H|D) = \\frac{p(D|H)p(H)}{p(D)}$$\n",
    "Let's pick apart the right-hand-side:\n",
    "* $p(D|H)$ this is the *likelihood*, which we saw in a previous lecture.  It's how likely we are to get data $D$ given that $H$ is the case.  It's often denoted $\\mathcal{L}(H)$ because the data is fixed.\n",
    "* $p(H)$ is the *prior probability*.  It is how likely we think $H$ is if we have no data at all to guide us.\n",
    "* $p(D)$ is the *evidence*, i.e. the probability of getting dataset $D$ unconditioned on a specific hypothesis $H$.  In general it is treated as a normalization constant, because the data set is fixed.  If we have a set of possible hypotheses and know that one of them must be the true hypothesis that generated the data, then we get that $p(D) = \\int p(D|H)p(H) dH$ to ensure that $p(H|D)$ integrates to 1 over all hypotheses. That is, \n",
    "$$1 = \\int p(H|D) dH = \\int \\frac{p(D|H)p(H)}{p(D)} dH = \\frac{1}{p(D)}\\int p(D|H)p(H) dH \\\\ \\rightarrow p(D) = \\int p(D|H)p(H) dH$$\n",
    "\n",
    "So, if we want to compute the probability of a hypothesis $H$ given some data $D$, we just need to compute the likelihood and choose a prior! For now we don't need to worry about the evidence, since it's just a normalization that we can compute at the very end.\n",
    "\n",
    "There are a few quantities we often want to compute with posterior distributions, namely the mean (expectation value), median (50th percentile value) and mode (maximum *a posteriori* value).  Let's quickly review them:\n",
    "* The mean of a random variable $X$ is the $X$ integrated against its probability density function.\n",
    "* The median of random variable $X$ is the value $X_{med}$ for which there is equal total probability above and below $X_{med}$.  \n",
    "\n",
    "## Classroom Example: The Monty Hall Problem\n",
    "A classic game-show game one hosted by Monty Hall.  In this game, a contestant must choose one of three doors A, B, and C and wins the prize behind the chosen door.  Behind two doors is a goat, and behind one is a car.  After the contestant has chosen a door, Monty opens one of the other two doors which has a goat behind it to show where one of the goats is.  The contestant now has the opportunity to switch to the other unopened door if they'd like.  Should the contestant switch?\n",
    "\n",
    "#### Think, Pair, Share\n",
    "With a partner, discuss the arguments for switching versus not switching.  Don't look at the solution below!\n",
    "\n",
    "\n",
    "#### Solution\n",
    "Let's look at this using Bayes' Rule. We'll say that the door originally chosen by the contestant is door A (the letters are just labels of the door, so we can call the door whatever we want).  Monty opens door B to show a goat.  We want to know the probability of the car being in door A versus door C given that door B has a goat behind it. In other words, we need to compute:\n",
    "\n",
    "$$p(\\textrm{A has car}|\\textrm{Monty opens B})$$\n",
    "Using Bayes' Rule:\n",
    "\n",
    "$$p(\\textrm{A has car}|\\textrm{Monty opens B}) = p(\\textrm{Monty opens B}|\\textrm{A has car})p(\\textrm{A has car})/p(\\textrm{Monty opens B})$$\n",
    "\n",
    "$p(\\textrm{Monty opens B}|\\textrm{A has car})$ is 0.5 because if the car is in door A, Monty is free to choose door B or door C to open, since both have goats.  $p(\\textrm{A has car})=1/3$, because under no other information, the car could equally likely be behind any of the doors.  $p(\\textrm{Monty opens B})$ is a little trickier.  We need to consider all the ways in which you might have chosen your first door, because Monty cannot open the door that you have chosen.  Analogously to computing the evidence integral, we get:\n",
    "\n",
    "$$p(\\textrm{Monty opens B}) = p(\\textrm{Monty opens B}|\\textrm{chose A})p(\\textrm{chose A}) + p(\\textrm{Monty opens B}|\\textrm{chose B})p(\\textrm{chose B}) + p(\\textrm{Monty opens B}|\\textrm{chose C})p(\\textrm{chose C})$$ \n",
    "\n",
    "The probability of choosing one of the doors first, say A, is $p(\\textrm{chose A}) = 1/3$ since all three doors are equally likely to be chosen by the contestant given no other information. $p(\\textrm{Monty opens B}|\\textrm{chose B}) = 0$ since Monty can't open door B if it's originally chosen by the contestant. Now $p(\\textrm{Monty opens B}|\\textrm{chose A})$ is a bit trickier to compute, because we don't know which door the car is actually behind.  Again, like the evidence integral, we can write:\n",
    "\n",
    "$$p(\\textrm{Monty opens B}|\\textrm{chose A}) = \\sum_{X = A,B,C}p(\\textrm{Monty opens B}|\\textrm{chose A, car behind X})p(\\textrm{car behind X})$$\n",
    "\n",
    "$p(\\textrm{car behind X})$ in all cases is (1/3), so computing this sum, we get $(1/3)*((1/2) + (0) + (1)) = 1/2$.  So now putting everything back together we find that \n",
    "\n",
    "$$p(\\textrm{A has car}|\\textrm{Monty opens B}) = \\frac{(1/2)(1/3)}{(1/2)} = \\frac{1}{3}$$\n",
    "\n",
    "This is a surprising result!! It *seems* like once Monty opens door B, the other goat is equally likely to be behind door A or C.  However this intuition turns out to be totally wrong!  Two-thirds of the time one should switch doors after Monty has shown one of the goat doors!  Why does the intuition fail here? Discuss with a partner.\n",
    "\n",
    "## Sampling\n",
    "Often times, one wants obtain samples from a PDF.  This is because it's easier to work with samples than it is to work with than the PDF itself. As an example, suppose the PDF of human heights $p(h)$ is described by a Gaussian.  Suppose now we want to compute the $p(f)$ where $f = f(h)$.  To do that, we need to use the chain rule: \n",
    "\n",
    "$$p(f) = \\frac{dP}{df} = \\frac{dP}{dh}\\frac{dh}{df} = p(h)\\frac{dh}{df}$$\n",
    "\n",
    "Note that we've used upper-case $P$ here to denote the cumulative probability $P$ between $f$ and $f+df$.  So it seems that if we want to know $p(f)$, we have to also know $\\frac{dh}{df}$, but in many practical cases, we don't know $\\frac{dh}{df}$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
